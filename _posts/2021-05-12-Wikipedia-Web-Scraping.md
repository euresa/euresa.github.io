---
layout: post
---

# Wikipedia Web Scraping

I recently saw a data science internship with the US Embassy in London requesting that individuals interested in the position write a script in Python capable of scraping a Wikipedia pages in order to match plain text data and hyperlinks to the titles of each of the subsections of the page. Although I've dabbled with web scraping Python modules in the past (such as BeautifulSoup), I had never really had a concrete objective to work towards and the projects I started tended to fizzle out. However, the challenge presented in the internship listing sounded quite interesting to me -- more interesting than the posting itself -- so I decided to go for it!.

I opted to carry out most of the NLP the Wikipedia HTML documents myself as opposed to heavily relying on a module already written. I'm sure there are easier ways to scrape Wikipedia pages (and web pages in general), but I enjoyed playing around with my own functions in order to solidly understand how things the processing is working. In the future, I hope to use some text from Wikipedia in orde to train some ML models. 